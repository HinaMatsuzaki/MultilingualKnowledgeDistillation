{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f30eb422-ae2e-4453-880c-ccbdd9ef9ea0",
   "metadata": {},
   "source": [
    "# MeCab\n",
    "MeCab is an open-source text segmentation library for use with text written in the Japanese language"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22d6359b-50a8-46e1-b6ce-e0f43f6e8f5b",
   "metadata": {},
   "source": [
    "##  List of Things to Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce313018-7e0b-4238-b958-427552e47a4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-06 19:55:01.364846: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-06 19:55:01.385207: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-06 19:55:01.385226: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-06 19:55:01.385243: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-06 19:55:01.389815: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-06 19:55:01.390304: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-06 19:55:01.860765: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import MeCab\n",
    "\n",
    "m = MeCab.Tagger(\"-Owakati\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe03942-5b2e-4368-9a09-54736d9a8b44",
   "metadata": {},
   "source": [
    "## Tokenize Japanese Sentences\n",
    "+ Load the dataset\n",
    "+ Extract Japanese sentences from the DataFrame into a list\n",
    "+ Tokenize the Japanese sentences\n",
    "+ Update the 'Japanese sentence' column in the DataFrame\n",
    "+ Save the updated DataFrame to a new CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7bf0052c-9820-4043-b89f-6fe601172aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(text):\n",
    "    return m.parse(text).strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e00ae0-ec60-4f32-a885-a36542ccf33e",
   "metadata": {},
   "source": [
    "### Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fd8cdf2-3a9c-4e81-b86a-4bceb9184099",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train_1M.tsv', sep='\\t', header=None, names=['English sentence', 'Japanese sentence'])\n",
    "ja_sentences_train = df_train['Japanese sentence'].tolist()\n",
    "tokenized_sentences_train = [parse(sentence) for sentence in ja_sentences_train]\n",
    "df_train['Japanese sentence'] = tokenized_sentences_train\n",
    "df_train.to_csv('train_1M_updated.tsv', sep='\\t', index=False, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a519917f-6212-4357-bab5-dc52cbe99fad",
   "metadata": {},
   "source": [
    "### Dev Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0f1785c-2680-4474-83d2-09ae1c53bb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dev = pd.read_csv('dev_large.tsv', sep='\\t', header=None, names=['English sentence', 'Japanese sentence', 'similarity score'])\n",
    "ja_sentences_dev = df_dev['Japanese sentence'].tolist()\n",
    "tokenized_sentences_dev = [parse(sentence) for sentence in ja_sentences_dev]\n",
    "df_dev['Japanese sentence'] = tokenized_sentences_dev\n",
    "df_dev.to_csv('dev_large_updated.tsv', sep='\\t', index=False, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d384a3d-6435-4880-a8b1-c5e60d7faee8",
   "metadata": {},
   "source": [
    "### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b6065ce-5899-48f9-b846-0030db7d8aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('test_large.tsv', sep='\\t', header=None, names=['English sentence', 'Japanese sentence'])\n",
    "ja_sentences_test = df_test['Japanese sentence'].tolist()\n",
    "tokenized_sentences_test = [parse(sentence) for sentence in ja_sentences_test]\n",
    "df_test['Japanese sentence'] = tokenized_sentences_test\n",
    "df_test.to_csv('test_large_updated.tsv', sep='\\t', index=False, header=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
